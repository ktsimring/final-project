{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import cm, pyplot as plt\n",
    "import pickle\n",
    "import warnings\n",
    "from math import sqrt\n",
    "import numpy\n",
    "import pyedflib\n",
    "import numpy as np\n",
    "import time\n",
    "start_time = time.time()\n",
    "np.random.seed(111)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "import keras\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "import pyedflib\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Hide messy TensorFlow warnings\n",
    "warnings.filterwarnings(\"ignore\") #Hide messy Numpy warnings\n",
    "\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale_t(data):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    data = data.reshape(-1, 1)\n",
    "    #scaler = StandardScaler()\n",
    "    scaler = scaler.fit(data)\n",
    "    # transform data\n",
    "    print(data.shape[0])\n",
    "    \n",
    "    data_scaled = scaler.transform(data)\n",
    "    \n",
    "    return scaler, data_scaled\n",
    " \n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X):\n",
    "    X = X.reshape(-1,1)\n",
    "    inverted = scaler.inverse_transform(X)\n",
    "    return inverted[:, 0]\n",
    "\n",
    "def load_data(filename):\n",
    "    g = pyedflib.EdfReader(filename)\n",
    "    n = g.signals_in_file\n",
    "    signal_labels = g.getSignalLabels()\n",
    "    sig = np.zeros((n, g.getNSamples()[0]))\n",
    "    for i in np.arange(n):\n",
    "        len_sig = len(g.readSignal(i))\n",
    "        sig[i, :len_sig] = g.readSignal(i)\n",
    "    return sig\n",
    "\n",
    "\n",
    "def chunk_data(diff, sequence_length):\n",
    "    chunk_data = np.zeros((diff.shape[0],diff.shape[1] - sequence_length, sequence_length))\n",
    "    for index in range(diff.shape[1] - sequence_length):\n",
    "        for k in range(diff.shape[0]):\n",
    "            chunk_data[k,index] = diff[k,index: index + sequence_length]\n",
    "    print(chunk_data[0,0])\n",
    "    return chunk_data\n",
    "\n",
    "def difference(datset, interval):\n",
    "    diff = np.zeros((dataset.shape[0],dataset.shape[1]))\n",
    "    for k in range(dataset.shape[0]):\n",
    "        for i in range(interval, dataset.shape[1]):\n",
    "            diff[k,i] = dataset[k,i] - dataset[k,i - interval]\n",
    "    return diff\n",
    "            \n",
    "\n",
    "# create a differenced series\n",
    "def normalize_all(result): \n",
    "    dataset = np.zeros(result.shape)\n",
    "    for i in range(result.shape[0]):\n",
    "        scaler, data_s = scale_t(result[i])\n",
    "        dataset[i] = data_s[:,0]\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def make_data(sig):\n",
    "    data = sig[:3,:360000*2]\n",
    "    data_scale = np.zeros(data.shape)\n",
    "    scalers = []\n",
    "    for i in range(data.shape[0]):\n",
    "        scaler, data_s = scale_t(data[i])\n",
    "        data_scale[i] = data_s[:,0]\n",
    "        scalers.append(scaler)\n",
    "    \n",
    "    row = round(0.9 * data_scale.shape[1])\n",
    "    data_scale = data_scale.T\n",
    "    train = data_scale[:int(row), :]\n",
    "    test = data_scale[int(row):, :]\n",
    "    \n",
    "    \n",
    "    #print(train_scaled.shape,test_scaled.shape)  \n",
    "    #print(train_scaled[0],test_scaled[0])\n",
    "    #np.random.shuffle(train)\n",
    "    return [scalers, train, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(predicted_data, true_data, make_line):\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    plt.plot(predicted_data, label='Prediction')\n",
    "    plt.legend()\n",
    "    if make_line:\n",
    "        plt.axvline(x=y_train.shape[0] + 1, linestyle='--', color = 'b', label = 'future predicted points')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading data... \n",
      "--- 4.5526638031 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print('> Loading data... ')\n",
    "sig = load_data('LSTM/sample-data/SC4002E0-PSG.edf')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720000\n",
      "720000\n",
      "720000\n",
      "((648000, 3), (72000, 3))\n"
     ]
    }
   ],
   "source": [
    "scalers, train, test = make_data(sig)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        47     1671926.2345          +0.3196\n",
      "        48     1671926.5395          +0.3050\n",
      "        49     1671926.8310          +0.2915\n",
      "        50     1671927.1099          +0.2789\n",
      "        51     1671927.3770          +0.2671\n",
      "        52     1671927.6330          +0.2560\n",
      "        53     1671927.8785          +0.2456\n",
      "        54     1671928.1142          +0.2357\n",
      "        55     1671928.3406          +0.2264\n",
      "        56     1671928.5582          +0.2175\n",
      "        57     1671928.7673          +0.2092\n",
      "        58     1671928.9686          +0.2012\n",
      "        59     1671929.1623          +0.1937\n",
      "        60     1671929.3487          +0.1865\n",
      "        61     1671929.5283          +0.1796\n",
      "        62     1671929.7014          +0.1731\n",
      "        63     1671929.8681          +0.1668\n",
      "        64     1671930.0289          +0.1608\n",
      "        65     1671930.1840          +0.1551\n",
      "        66     1671930.3337          +0.1496\n",
      "        67     1671930.4781          +0.1444\n",
      "        68     1671930.6175          +0.1394\n",
      "        69     1671930.7521          +0.1346\n",
      "        70     1671930.8821          +0.1300\n",
      "        71     1671931.0078          +0.1256\n",
      "        72     1671931.1292          +0.1214\n",
      "        73     1671931.2466          +0.1174\n",
      "        74     1671931.3601          +0.1135\n",
      "        75     1671931.4699          +0.1098\n",
      "        76     1671931.5762          +0.1062\n",
      "        77     1671931.6790          +0.1028\n",
      "        78     1671931.7786          +0.0995\n",
      "        79     1671931.8750          +0.0964\n",
      "        80     1671931.9683          +0.0934\n",
      "        81     1671932.0588          +0.0905\n",
      "        82     1671932.1465          +0.0877\n",
      "        83     1671932.2315          +0.0850\n",
      "        84     1671932.3139          +0.0824\n",
      "        85     1671932.3939          +0.0799\n",
      "        86     1671932.4714          +0.0776\n",
      "        87     1671932.5467          +0.0753\n",
      "        88     1671932.6197          +0.0731\n",
      "        89     1671932.6906          +0.0709\n",
      "        90     1671932.7595          +0.0689\n",
      "        91     1671932.8264          +0.0669\n",
      "        92     1671932.8914          +0.0650\n",
      "        93     1671932.9546          +0.0632\n",
      "        94     1671933.0160          +0.0614\n",
      "        95     1671933.0757          +0.0597\n",
      "        96     1671933.1337          +0.0581\n",
      "        97     1671933.1902          +0.0565\n",
      "        98     1671933.2451          +0.0549\n",
      "        99     1671933.2986          +0.0535\n",
      "       100     1671933.3506          +0.0520\n",
      "       101     1671933.4013          +0.0507\n",
      "       102     1671933.4506          +0.0493\n",
      "       103     1671933.4986          +0.0480\n",
      "       104     1671933.5454          +0.0468\n",
      "       105     1671933.5910          +0.0456\n",
      "       106     1671933.6354          +0.0444\n",
      "       107     1671933.6787          +0.0433\n",
      "       108     1671933.7209          +0.0422\n",
      "       109     1671933.7621          +0.0412\n",
      "       110     1671933.8022          +0.0401\n",
      "       111     1671933.8413          +0.0391\n",
      "       112     1671933.8795          +0.0382\n",
      "       113     1671933.9168          +0.0372\n",
      "       114     1671933.9531          +0.0363\n",
      "       115     1671933.9886          +0.0355\n",
      "       116     1671934.0232          +0.0346\n",
      "       117     1671934.0569          +0.0338\n",
      "       118     1671934.0899          +0.0330\n",
      "       119     1671934.1221          +0.0322\n",
      "       120     1671934.1536          +0.0314\n",
      "       121     1671934.1843          +0.0307\n",
      "       122     1671934.2143          +0.0300\n",
      "       123     1671934.2436          +0.0293\n",
      "       124     1671934.2722          +0.0286\n",
      "       125     1671934.3002          +0.0280\n",
      "       126     1671934.3275          +0.0273\n",
      "       127     1671934.3543          +0.0267\n",
      "       128     1671934.3804          +0.0261\n",
      "       129     1671934.4059          +0.0255\n",
      "       130     1671934.4308          +0.0249\n",
      "       131     1671934.4552          +0.0244\n",
      "       132     1671934.4791          +0.0239\n",
      "       133     1671934.5023          +0.0233\n",
      "       134     1671934.5251          +0.0228\n",
      "       135     1671934.5474          +0.0223\n",
      "       136     1671934.5692          +0.0218\n",
      "       137     1671934.5905          +0.0213\n",
      "       138     1671934.6114          +0.0208\n",
      "       139     1671934.6318          +0.0204\n",
      "       140     1671934.6517          +0.0199\n",
      "       141     1671934.6712          +0.0195\n",
      "       142     1671934.6903          +0.0191\n",
      "       143     1671934.7090          +0.0187\n",
      "       144     1671934.7272          +0.0183\n",
      "       145     1671934.7451          +0.0179\n",
      "       146     1671934.7626          +0.0175\n",
      "       147     1671934.7797          +0.0171\n",
      "       148     1671934.7964          +0.0167\n",
      "       149     1671934.8128          +0.0164\n",
      "       150     1671934.8288          +0.0160\n",
      "       151     1671934.8445          +0.0157\n",
      "       152     1671934.8598          +0.0154\n",
      "       153     1671934.8748          +0.0150\n",
      "       154     1671934.8895          +0.0147\n",
      "       155     1671934.9039          +0.0144\n",
      "       156     1671934.9180          +0.0141\n",
      "       157     1671934.9317          +0.0138\n",
      "       158     1671934.9452          +0.0135\n",
      "       159     1671934.9584          +0.0132\n",
      "       160     1671934.9713          +0.0129\n",
      "       161     1671934.9839          +0.0126\n",
      "       162     1671934.9962          +0.0123\n",
      "       163     1671935.0083          +0.0120\n",
      "       164     1671935.0201          +0.0118\n",
      "       165     1671935.0317          +0.0116\n",
      "       166     1671935.0430          +0.0113\n",
      "       167     1671935.0541          +0.0111\n",
      "       168     1671935.0649          +0.0108\n",
      "       169     1671935.0755          +0.0106\n",
      "       170     1671935.0859          +0.0104\n",
      "       171     1671935.0960          +0.0102\n",
      "       172     1671935.1060          +0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00383045 -0.05216758 -0.01588151]\n",
      " [ 0.0231715  -0.03092811 -0.24610446]\n",
      " [ 0.01513188 -0.06221164  0.21571543]\n",
      " [ 0.15122805 -0.025669   -0.02013773]]\n",
      "[[[0.00522627 0.         0.        ]\n",
      "  [0.         0.00440787 0.        ]\n",
      "  [0.         0.         0.00354443]]\n",
      "\n",
      " [[0.04229854 0.         0.        ]\n",
      "  [0.         0.01138309 0.        ]\n",
      "  [0.         0.         0.01798454]]\n",
      "\n",
      " [[0.04326808 0.         0.        ]\n",
      "  [0.         0.01239873 0.        ]\n",
      "  [0.         0.         0.02195267]]\n",
      "\n",
      " [[0.00628779 0.         0.        ]\n",
      "  [0.         0.00593941 0.        ]\n",
      "  [0.         0.         0.00596429]]]\n",
      "[1.0000000e+000 0.0000000e+000 4.7540738e-136 0.0000000e+000]\n",
      "[[0.96591175 0.00939899 0.00977982 0.01490944]\n",
      " [0.01243545 0.97258078 0.00266294 0.01232084]\n",
      " [0.01512916 0.00241278 0.97179537 0.01066269]\n",
      " [0.02925115 0.01265147 0.01235118 0.9457462 ]]\n",
      "(648000,)\n"
     ]
    }
   ],
   "source": [
    "model_3 = hmm.GaussianHMM(n_components=4, covariance_type=\"diag\", n_iter = 500, verbose=True).fit(train)\n",
    "print(model_3.means_)\n",
    "print(model_3.covars_)\n",
    "print(model_3.startprob_)\n",
    "print(model_3.transmat_)\n",
    "z = model_3.predict(train)\n",
    "print z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(train.shape[1]):\n",
    "    fig, axs = plt.subplots(model_3.n_components+1, sharex=True, sharey=True)\n",
    "    colours = cm.rainbow(np.linspace(0, 1, model_3.n_components))\n",
    "    time = np.arange(0,100, 1/100)\n",
    "    axs[0].plot(time, train[:10000,k])\n",
    "    axs[0].set_title(\"EEG train data for channel %d \" % k)\n",
    "    axs[0].grid(True)\n",
    "    train_k = train[:,k]\n",
    "    \n",
    "    for i  in range(1,model_3.n_components+1):\n",
    "        mask = z == i-1\n",
    "        #print(time[mask])\n",
    "        axs[i].plot(time[mask], train_k[mask], \".-\", c=colours[i-1])\n",
    "        axs[i].set_title(\"#{0} hidden state\".format(i-1))\n",
    "\n",
    "        axs[i].grid(True)\n",
    "    \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import check_random_state\n",
    "\n",
    "L=len(test) # We would like to predict the following 15 days' trend\n",
    "Niter = 10 # A hyper parameter of generating samples\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "eeg0 = train\n",
    "eeg2 = np.copy(train)\n",
    "\n",
    "startprob_cdf = np.cumsum(model_3.startprob_)\n",
    "transmat_cdf = np.cumsum(model_3.transmat_, axis=1)\n",
    "random_state = model_3.random_state\n",
    "\n",
    "rs = check_random_state(None)\n",
    "\n",
    "for l in range(L):\n",
    "    eeg2 = np.append(eeg2,[[0,0,0]],axis=0) # Add a pair of empty (d,v)\n",
    "    true_eeg = np.copy(eeg0[:len(train)+l])\n",
    "    #print(true_eeg.shape)\n",
    "    state_seq = model_3.predict(true_eeg)\n",
    "    previous_state = state_seq[-1]\n",
    "\n",
    "    maxLL = -1e10\n",
    "    for n in range(Niter):\n",
    "        currstate = (transmat_cdf[previous_state]> rs.rand() ).argmax() # Go through transmat to get a new state\n",
    "\n",
    "        new_sample = model_3._generate_sample_from_state(currstate) # generate from the new state\n",
    "        tmp_eeg = np.copy(true_eeg)\n",
    "        tmp_eeg = np.append(tmp_eeg,[new_sample],axis=0) # Append the new_sample for score\n",
    "        tmp_maxLL = model_3.score(tmp_eeg) # \n",
    "        if tmp_maxLL > maxLL :\n",
    "\n",
    "                maxLL = tmp_maxLL\n",
    "                eeg2[-1] = new_sample[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Training duration (s) : ', time.time() - global_start_time)\n",
    "true_data = np.zeros((3,len(eeg2)))\n",
    "pred_data = eeg2.T\n",
    "y_train = train.T\n",
    "y_test = test.T\n",
    "cut_off = int(0.9*(true_data.shape[1]))\n",
    "for i in range(true_data.shape[0]): \n",
    "    plot_results(pred_data[i, :500], y_train[i,:500], False)\n",
    "    true_data[i,:] = np.concatenate([y_train[i,:],y_test[i,:]])\n",
    "    plot_results(pred_data[i,:], true_data[i,:], True)\n",
    "    plot_results(pred_data[i,cut_off:], y_test[i, :], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "tot_time_length = 10000\n",
    "#seg_time_length = 10000 - seq_len\n",
    "nchannels = pred_data.shape[0]\n",
    "params = {'tot_time_length': tot_time_length, 'cut_off': cut_off, 'nchannels': nchannels}\n",
    "data = {'true_data': true_data, 'pred_data': pred_data}\n",
    "with open('LSTM/output-data/3channel_HMM_data_SC4002E0-PSG.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump(params, f)\n",
    "    pickle.dump(scalers, f)\n",
    "    pickle.dump(pred_data, f)\n",
    "    pickle.dump(true_data, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
